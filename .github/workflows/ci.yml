name: ci

on:
  push:
    branches:
      - stage
  workflow_dispatch:

permissions:
  contents: read

jobs:
  dataflow-grammar:
    permissions:
      contents: read
      actions: read
    if: github.event_name != 'workflow_dispatch' || (github.ref == 'refs/heads/stage' && github.actor == github.repository_owner)
    runs-on: ubuntu-latest
    timeout-minutes: 70
    env:
      MISE_TRUSTED_CONFIG_PATHS: ${{ github.workspace }}
    steps:
      # Allow-listed actions: actions/checkout, jdx/mise-action
      - name: Checkout
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd
        with:
          fetch-depth: 0
      - name: Install mise
        uses: jdx/mise-action@6d1e696aa24c1aa1bcc1adea0212707c71ab78a8
      - name: Install toolchain
        run: mise install
      - name: Create venv
        run: |
          mise exec -- python -m venv .venv
          echo "VIRTUAL_ENV=$PWD/.venv" >> $GITHUB_ENV
          echo "$PWD/.venv/bin" >> $GITHUB_PATH
      - name: Install dependencies (locked)
        run: |
          .venv/bin/python -m pip install --upgrade pip uv
          .venv/bin/uv pip sync requirements.lock
          .venv/bin/uv pip install -e .
      - name: Seed version-controlled dataflow resume checkpoint (best effort)
        run: .venv/bin/python scripts/ci_seed_dataflow_checkpoint.py
      - name: Restore previous dataflow resume checkpoint (best effort)
        env:
          GH_TOKEN: ${{ github.token }}
          GH_REPO: ${{ github.repository }}
          GH_REF_NAME: ${{ github.ref_name }}
          GH_RUN_ID: ${{ github.run_id }}
        run: |
          .venv/bin/python -m gabion restore-resume-checkpoint \
            --output-dir artifacts/audit_reports \
            --artifact-name dataflow-report \
            --checkpoint-name dataflow_resume_checkpoint_ci.json
      - name: Dataflow audit invocation
        id: dataflow_stage
        run: |
          .venv/bin/python -m gabion \
            --transport direct \
            --lsp-timeout-ticks 65000000 \
            --lsp-timeout-tick-ns 1000000 \
            run-dataflow-stage \
            --debug-dump-interval-seconds 60 \
            --stage-strictness-profile "run=high"
      - name: Finalize dataflow audit outcome
        if: always()
        env:
          TERMINAL_EXIT: ${{ steps.dataflow_stage.outputs.exit_code }}
          TERMINAL_STATE: ${{ steps.dataflow_stage.outputs.analysis_state }}
          TERMINAL_STAGE: ${{ steps.dataflow_stage.outputs.terminal_stage }}
          TERMINAL_STATUS: ${{ steps.dataflow_stage.outputs.terminal_status }}
          ATTEMPTS_RUN: ${{ steps.dataflow_stage.outputs.attempts_run }}
        run: |
          .venv/bin/python scripts/ci_finalize_dataflow_outcome.py \
            --terminal-exit "${TERMINAL_EXIT:-}" \
            --terminal-state "${TERMINAL_STATE:-none}" \
            --terminal-stage "${TERMINAL_STAGE:-none}" \
            --terminal-status "${TERMINAL_STATUS:-unknown}" \
            --attempts-run "${ATTEMPTS_RUN:-0}"
      - name: Deadline profile summary
        if: always()
        run: |
          if [ -f artifacts/out/deadline_profile.json ]; then
            .venv/bin/python scripts/deadline_profile_ci_summary.py \
              --allow-missing-local \
              --step-summary "$GITHUB_STEP_SUMMARY"
          else
            echo "Skipping deadline profile summary (missing artifacts/out/deadline_profile.json)." \
              | tee -a "$GITHUB_STEP_SUMMARY"
          fi
      - name: Upload dataflow report
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: dataflow-report
          path: |
            artifacts/audit_reports/dataflow_report.md
            artifacts/audit_reports/dataflow_report_stage_*.md
            artifacts/audit_reports/timeout_progress.md
            artifacts/audit_reports/timeout_progress.json
            artifacts/audit_reports/timeout_progress_stage_*.md
            artifacts/audit_reports/timeout_progress_stage_*.json
            artifacts/audit_reports/dataflow_resume_checkpoint_ci.json
            artifacts/audit_reports/dataflow_resume_checkpoint_ci.json.chunks/**
            artifacts/audit_reports/dataflow_checkpoint_intro_timeline.md
            artifacts/out/deadline_profile.json
            artifacts/out/deadline_profile.md
            artifacts/out/deadline_profile_stage_*.json
            artifacts/out/deadline_profile_stage_*.md
            artifacts/out/deadline_profile_ci_summary.json
            artifacts/out/deadline_profile_ci_summary.md

  checks:
    name: audit
    if: github.event_name != 'workflow_dispatch' || (github.ref == 'refs/heads/stage' && github.actor == github.repository_owner)
    runs-on: ubuntu-latest
    env:
      MISE_TRUSTED_CONFIG_PATHS: ${{ github.workspace }}
    steps:
      # Allow-listed actions: actions/checkout, jdx/mise-action
      - name: Checkout
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd
        with:
          fetch-depth: 0
      - name: Install mise
        uses: jdx/mise-action@6d1e696aa24c1aa1bcc1adea0212707c71ab78a8
      - name: Install toolchain
        run: mise install
      - name: Create venv
        run: |
          mise exec -- python -m venv .venv
          echo "VIRTUAL_ENV=$PWD/.venv" >> $GITHUB_ENV
          echo "$PWD/.venv/bin" >> $GITHUB_PATH
      - name: Install dependencies (locked)
        run: |
          .venv/bin/python -m pip install --upgrade pip uv
          .venv/bin/uv pip sync requirements.lock
          .venv/bin/uv pip install -e .
      - name: Policy check (workflows)
        run: .venv/bin/python scripts/policy_check.py --workflows
      - name: Policy check (ambiguity contract)
        run: .venv/bin/python scripts/policy_check.py --ambiguity-contract
      - name: Policy check (posture)
        if: github.event_name == 'push'
        env:
          POLICY_GITHUB_TOKEN: ${{ secrets.POLICY_GITHUB_TOKEN }}
        run: |
          if [ -z "${POLICY_GITHUB_TOKEN:-}" ]; then
            echo "POLICY_GITHUB_TOKEN not set; skipping posture check."
            exit 0
          fi
          .venv/bin/python scripts/policy_check.py --posture
      - name: Docflow audit
        run: .venv/bin/python -m gabion docflow --root . --fail-on-violations --sppf-gh-ref-mode required
      - name: SPPF status drift audit
        run: .venv/bin/python scripts/sppf_status_audit.py --root .
      - name: SPPF issue lifecycle validation (non-mutating)
        if: github.event_name == 'push'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          BEFORE_SHA: ${{ github.event.before }}
          AFTER_SHA: ${{ github.sha }}
        run: |
          if [ -z "${GH_TOKEN:-}" ]; then
            echo "GH_TOKEN is unavailable; skipping SPPF issue lifecycle validation."
            exit 0
          fi
          if [ -z "${BEFORE_SHA:-}" ] || [ "$BEFORE_SHA" = "0000000000000000000000000000000000000000" ]; then
            rev_range="HEAD~20..HEAD"
          else
            if ! git cat-file -e "${AFTER_SHA}^{commit}" 2>/dev/null || ! git cat-file -e "${BEFORE_SHA}^{commit}" 2>/dev/null; then
              git fetch --no-tags origin "$BEFORE_SHA" "$AFTER_SHA" || true
            fi

            if git cat-file -e "${AFTER_SHA}^{commit}" 2>/dev/null && git cat-file -e "${BEFORE_SHA}^{commit}" 2>/dev/null; then
              rev_range="$BEFORE_SHA..$AFTER_SHA"
            else
              echo "Push SHAs unavailable locally; falling back to safe local range."
              rev_range="HEAD~20..HEAD"
            fi
          fi
          .venv/bin/python scripts/sppf_sync.py \
            --validate \
            --only-when-relevant \
            --range "$rev_range" \
            --require-state open \
            --require-label done-on-stage \
            --require-label status/pending-release
      - name: Test evidence index
        env:
          GABION_LSP_TIMEOUT_TICKS: "300000"
          GABION_LSP_TIMEOUT_TICK_NS: "1000000"
        run: |
          .venv/bin/python scripts/extract_test_evidence.py --root . --tests tests --out out/test_evidence.json
          git diff --exit-code out/test_evidence.json
      - name: Policy check (no monkeypatch)
        run: .venv/bin/python scripts/no_monkeypatch_policy_check.py --root .
      - name: Policy check (branchless)
        run: .venv/bin/python scripts/branchless_policy_check.py --root .
      - name: Policy check (defensive fallback)
        run: .venv/bin/python scripts/defensive_fallback_policy_check.py --root .
      - name: Restore controller drift gate history
        continue-on-error: true
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          BRANCH_NAME: ${{ github.ref_name }}
        run: |
          mkdir -p artifacts/out
          if [ -z "${GH_TOKEN:-}" ]; then
            echo "GH_TOKEN unavailable; skipping controller drift history restore."
            exit 0
          fi
          history_url=$(gh api \
            "repos/${{ github.repository }}/actions/artifacts" \
            --paginate \
            -f per_page=100 \
            --jq '.artifacts[] | select(.name == "controller-drift-gate-history" and .expired == false and .workflow_run.head_branch == env.BRANCH_NAME) | .archive_download_url' \
            | head -n 1)
          if [ -z "${history_url:-}" ]; then
            echo "No prior controller drift history artifact found for branch ${BRANCH_NAME}."
            exit 0
          fi
          gh api "$history_url" > artifacts/out/controller_drift_gate_history.zip
          python -c 'import zipfile; from pathlib import Path; z=Path("artifacts/out/controller_drift_gate_history.zip"); zipfile.ZipFile(z).extractall("artifacts/out"); z.unlink(missing_ok=True)'
      - name: Controller drift audit
        run: .venv/bin/python scripts/governance_controller_audit.py --out artifacts/out/controller_drift.json
      - name: Override lifecycle record emit
        run: .venv/bin/python scripts/ci_override_record_emit.py --out artifacts/out/governance_override_record.json
      - name: Controller drift gate
        run: |
          .venv/bin/python scripts/ci_controller_drift_gate.py \
            --drift-artifact artifacts/out/controller_drift.json \
            --override-record artifacts/out/governance_override_record.json \
            --history artifacts/out/controller_drift_gate_history.json
      - name: LSP parity gate
        run: .venv/bin/python -m gabion lsp-parity-gate --command gabion.check
      - name: Tests
        run: |
          mkdir -p artifacts/test_runs
          .venv/bin/python -m pytest \
            --cov=src/gabion \
            --cov-branch \
            --cov-report=term-missing \
            --cov-report=xml:artifacts/test_runs/coverage.xml \
            --cov-report=html:artifacts/test_runs/htmlcov \
            --cov-fail-under=100 \
            --junitxml artifacts/test_runs/junit.xml \
            --log-file artifacts/test_runs/pytest.log \
            --log-file-level=INFO
      - name: Delta state emit
        run: |
          .venv/bin/python -m gabion \
            --transport direct \
            --lsp-timeout-ticks 65000000 \
            --lsp-timeout-tick-ns 1000000 \
            delta-state-emit
      - name: Delta triplets (default-on burn-down gates)
        run: |
          .venv/bin/python -m gabion \
            --transport direct \
            --lsp-timeout-ticks 65000000 \
            --lsp-timeout-tick-ns 1000000 \
            delta-triplets
      - name: Governance telemetry emit
        run: |
          .venv/bin/python scripts/governance_telemetry_emit.py \
            --run-id "${{ github.run_id }}-${{ github.run_attempt }}" \
            --timings artifacts/audit_reports/ci_step_timings.json \
            --history artifacts/out/governance_telemetry_history.json \
            --json-out artifacts/out/governance_telemetry.json \
            --md-out artifacts/audit_reports/governance_telemetry.md
      - name: Upload controller drift gate history
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: controller-drift-gate-history
          path: artifacts/out/controller_drift_gate_history.json
      - name: Upload test artifacts
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: test-runs
          path: |
            artifacts/test_runs
            artifacts/out/governance_telemetry.json
            artifacts/out/governance_telemetry_history.json
            artifacts/out/controller_drift_gate_history.json
            artifacts/audit_reports/governance_telemetry.md
